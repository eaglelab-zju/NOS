# Towards an Inclusive Mobile Web: A Dataset and Framework for Focusability in UI Accessibility (WWW'25 Web4Good) 

ðŸ“„ Read the full paper here [Link](https://dl.acm.org/doi/10.1145/3696410.3714523).

## Installation

- python>=3.8
- for installation scripts see .ci/install-dev.sh, .ci/install.sh

```sh
bash .ci/install-dev.sh
bash .ci/install.sh
```

## Dataset: NOS [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.14802776.svg)](https://doi.org/10.5281/zenodo.14802776) & NOS-raw [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.14808245.svg)](https://doi.org/10.5281/zenodo.14808244)

### Download

Check the DOI url or the following google driver urls:

- extra-nos-raw-labeled
    - [download-url](https://drive.google.com/file/d/1PGznhGlPKjEXatq0Sh3cVUuqx5beOfHF/view?usp=sharing)
    - train/predict now-raw-labeled needed, you can download or generate by script
- extra-rico-labeled
    - [download-url](https://drive.google.com/file/d/1MwuhkmBbyLtWzBKyRWf8oaVofwKu1rp5/view?usp=sharing)
    - train/predict rico-labeled needed, you can download or generate by script
- nos-raw-labeled
    - [download-url](https://drive.google.com/file/d/1L0TofPa66H98vM86beLMjswpveLjoHTT/view?usp=sharing)
    - train/predict now-raw-labeled needed
- rico-labeled
    - [download-url](https://drive.google.com/file/d/11MLqeLgibZo2jPf9UuQtJPe08aPqxNJS/view?usp=sharing)
    - train/predict rico-labeled needed
- mixed-split 
    - [download-url](https://drive.google.com/file/d/19CQATtbjdSmuMV5CF6m4rRe7mqk_uL3T/view?usp=sharing)
    - train/predict mixed needed, dataset split for mixed experiments
- weights
    - [download-url](https://drive.google.com/file/d/1zV2s5r74GLxNlwJJsUKS8o4TrAR85R0X/view?usp=sharing)
    - predict needed, trained model weights

### Organize the directory structure

- downloaded directory structure

```sh
.
â”œâ”€â”€ extra-nos-raw-labeled
â”‚   â”œâ”€â”€ box
â”‚   â”œâ”€â”€ box_feat
â”‚   â”œâ”€â”€ graph
â”‚   â””â”€â”€ text_feat
â”œâ”€â”€ extra-rico-labeled
â”‚   â”œâ”€â”€ box
â”‚   â”œâ”€â”€ box_feat
â”‚   â”œâ”€â”€ graph
â”‚   â””â”€â”€ text_feat
â”œâ”€â”€ nos-raw-labeled
â”‚   â”œâ”€â”€ hierarchy
â”‚   â””â”€â”€ screenshot
â”œâ”€â”€ rico-labeled
â”‚   â”œâ”€â”€ hierarchy
â”‚   â””â”€â”€ screenshot
â”œâ”€â”€ mixed-split
â””â”€â”€ weights
    â”œâ”€â”€ mixed
    â”œâ”€â”€ nos-raw-labeled
    â””â”€â”€ rico-labeled
```

- you should put the dataset into `NOS/dataset`

```sh
cd NOS
mkdir dataset
mv ${nos-raw-labeled-path} ./dataset/nos-raw-labeled
mv ${rico-labeled-path}    ./dataset/rico-labeled
```

- if you has downloaded the `extra` part, you need to run:

```sh
mv ${extra-nos-raw-labeled-path}/* ./dataset/nos-raw-labeled
mv ${extra-rico-labeled-path}/*    ./dataset/rico-labeled
```

- otherwise, you need generate the `extra` part by:

```sh
# first edit the file `preprocess.py`
line 14 dataset_dir = "./dataset/nos-raw-labeled" <-- choose one dataset
line 15 # dataset_dir = "./dataset/rico-labeled" <-- and comment the another line

# then run the preprocess script to generate `box` `box_feat` `graph` `text_feat` (about 30min per dataset)
python preprocess.py

# for dataset `nos-raw` and `rico`, you should repeat the above steps twice
```

- finally, the `NOS` workspace will be:

```sh
.
â”œâ”€â”€ dataset
â”‚   â”œâ”€â”€ nos-raw-labeled
â”‚   â”‚   â”œâ”€â”€ box
â”‚   â”‚   â”œâ”€â”€ box_feat
â”‚   â”‚   â”œâ”€â”€ graph
â”‚   â”‚   â”œâ”€â”€ hierarchy
â”‚   â”‚   â”œâ”€â”€ screenshot
â”‚   â”‚   â”œâ”€â”€ text_feat
â”‚   â”‚   â””â”€â”€ dataset_split_{1,2,3}.json
â”‚   â”œâ”€â”€ rico-labeled
â”‚   â”‚   â”œâ”€â”€ box
â”‚   â”‚   â”œâ”€â”€ box_feat
â”‚   â”‚   â”œâ”€â”€ graph
â”‚   â”‚   â”œâ”€â”€ hierarchy
â”‚   â”‚   â”œâ”€â”€ screenshot
â”‚   â”‚   â”œâ”€â”€ text_feat
â”‚   â”‚   â””â”€â”€ dataset_split_{1,2,3}.json
â”‚   â””â”€â”€ mixed # combine the contents of the two folders `nos-raw-labeled` and `rico-labeled`
â”‚       â”œâ”€â”€ box
â”‚       â”œâ”€â”€ box_feat
â”‚       â”œâ”€â”€ graph
â”‚       â”œâ”€â”€ hierarchy
â”‚       â”œâ”€â”€ screenshot
â”‚       â”œâ”€â”€ text_feat
â”‚       â””â”€â”€ dataset_split_{1,2,3}.json
â”œâ”€â”€ main.py
â”œâ”€â”€ config.py
â”œâ”€â”€ data_loader.py
â”œâ”€â”€ model.py
â”œâ”€â”€ predict.py
â”œâ”€â”€ utils.py
â””â”€â”€ IGNN
```

## Method: GIFT [![CODE DOI](https://zenodo.org/badge/919884401.svg)](https://doi.org/10.5281/zenodo.14803014)

### Predict

- copy the checkpoint file

```sh
mkdir -p ./model_checkpoint/ignn/nos-raw-labeled_split_1
mkdir -p ./model_checkpoint/ignn/rico-labeled_split_1

mv ${weights-path}/nos-raw-labeled/split_1.pt ./model_checkpoint/ignn/nos-raw-labeled_split_1
mv ${weights-path}/rico-labeled/split_1.pt    ./model_checkpoint/ignn/rico-labeled_split_1
```

- run command

```sh
source .env/bin/activate

python -u main.py --mode predict --checkpoint split_1 --dataset nos-raw --split 1 --gpu 0
python -u main.py --mode predict --checkpoint split_1 --dataset rico    --split 1 --gpu 0
```

- then you can see the result in `./predict_result/ignn`

### Train

- run command

```sh
source .env/bin/activate

python -u main.py --dataset nos-raw  --split 1 --mode train --gpu 0
python -u main.py --dataset rico     --split 1 --mode train --gpu 0
```

- the checkpoint will be saved in `./model_checkpoint/ignn`

## Citation

```bibtex
@inproceedings{10.1145/3696410.3714523,
title = {Towards an Inclusive Mobile Web: A Dataset and Framework for Focusability in UI Accessibility},
author = {Gu, Ming and Pei, Lei and Zhou, Sheng and Shen, Ming and Wu, Yuxuan and Gao, Zirui and Wang, Ziwei and Shan, Shuo and Jiang, Wei and Li, Yong and Bu, Jiajun},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {5096â€“5107},
numpages = {12},
year = {2025}
}
```